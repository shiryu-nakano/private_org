#+title: 2025-12-12
#+filetags: :daily:

* 直近の予定締め切り

* TASK

* LOG
** 2025-12-12 09:07  :B4:
- vitについて調べる
  - [ ] 文献を3つ見つけた．
    これらはvitの発達段階に関係するもの．
  - [ ] Emergence of Human-Like Attention in Self-Supervised Vision Transformers
    視線がわかるなら，発達段階でもわかるのでは？
    この論文で提案した学習手法がtureなら，その上で発達段階中の子供がどんなところを見ているのかもわかるし，その上で
    モデルのLLCを見ることでモジュール文化が理解できるかもしれない？？？？？
    [[https://resou.osaka-u.ac.jp/ja/research/2025/20250530_1][人工知能が人と同じ視線を獲得した！ - ResOU]]
    - 情報量を最大化する自発的な学習を行ったビジョン・トランスフォーマー(ViT)と呼ばれる人工知能が、人間と極めてよく似た場所を見るように「育つ」ことを発見。
    - 人間の脳がどのように視覚情報を処理し、どこに注意を向けるのかはまだ完全に理解されていないため、人間のような注意機構をAIで再現することは困難だった。
    - ViTは、場面を「人や物の中心」、「人や物の全体」、「場面の背景」の3群に分解して注意を向けていることから、人間もViTのように世界を3群に分けて理解している可能性が示唆された。
    - DINO法を使うと学習済みモデルの視点が人間に近くなる．
    - [ ] attention headごとのクラスタリングをしたみたいだが，それはどうやってやったのか？

   #+begin_src
     attention head のクラスタリングは、各 attention head の注意行動を数値化 → 距離行列を作成 → 次元削減/クラスタリング手法で分類する流れで行われています。
   #+end_src

  - [ ] How Does Attention Work in Vision Transformers? A Visual Analytics Attempt
    
  - [ ] Teaching Matters: Investigating the Role of Supervision in Vision Transformers

  - [ ] Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?
    
  - 調べる上でのめもなど
    - パッチ埋込って何？
    - オブジェクト結合って何？
      
* タスク整理

* 所感

